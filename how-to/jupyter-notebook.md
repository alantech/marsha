# Jupyter Notebook meets Marsha! ü§ù

It is incredible to see how people with different backgrounds and experts in diverse domains are genuinely intrigued and amazed by the potential of LLMs (Large Language Models). And how could they not be? Since LLMs have become widely available for everyone, they have opened up a world of possibilities. Some people have started using these tools to get answers about their businesses and ways to improve them. Others are seeking ways to integrate these tools into their current workflows to be more productive.

In the tech industry, you can find countless articles discussing how LLMs have helped improve productivity. This holds true when these tools, such as ChatGPT, GPT Engineer, Github Copilot, etc., are used wisely. They can accelerate workflows by addressing challenges like the so-called "Cold start" problem, offering boilerplate code to kickstart projects, or assisting with tedious or repetitive tasks.

All of these articles, especially the ones discussing how to use code generation tools, converge on one crucial point: the generated response cannot be solely relied upon. While it may appear almost perfect, more often than not, it requires some level of human interaction to address small typos or bugs. The more complex the task, the higher the probability of errors occurring.

Another consideration to take into account is the ease of integration with these new tools. Initially, when using tools like ChatGPT, there was a significant amount of context switching required. However, over time, numerous wrappers and plugins have been developed, to significantly simplify the integration process and meet the users where they are at.

One of those developed tools that have come to help in terms of LLM code reliability is [Marsha](https://github.com/alantech/marsha).

## What (or who? üëÄ) is Marsha?

As the GitHub page explains, Marsha is an LLM-based programming language. Based on an English description of what you want to do and some examples of usage following a simple syntax, the Marsha compiler will guide an LLM to produce **tested** Python software.

## So, what can Marsha actually do?

<!-- Explain capabilities and lint to examples folder? -->

<!-- Focus on notebook example for this post, creating step by step with images showing how can marsha be integrated in the workflow -->
